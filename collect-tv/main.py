import urllib.request
import re #æ­£åˆ™
import os
from datetime import datetime
import requests
import time
from txt2m3u import m3u_to_txt
import sys
import cv2
import ffmpeg
import numpy as np
import subprocess
from bs4 import BeautifulSoup
import zhconv

def time_str(fmt=None):
    if fmt is None:
        fmt = '%Y_%m_%d_%H_%M_%S'
    return datetime.datetime.today().strftime(fmt)
       

def process_name_string(input_str):
    parts = input_str.split(',')
    processed_parts = []
    for part in parts:
        processed_part = process_part(part)
        processed_parts.append(processed_part)
    result_str = ','.join(processed_parts)
    return result_str

def process_part(part_str):
    # å¤„ç†é€»è¾‘
    if "CCTV" in part_str:
        part_str=part_str.replace("IPV6", "")  #å…ˆå‰”é™¤IPV6å­—æ ·
        filtered_str = ''.join(char for char in part_str if char.isdigit() or char == 'K' or char == '+')
        if not filtered_str.strip(): #å¤„ç†ç‰¹æ®Šæƒ…å†µï¼Œå¦‚æœå‘ç°æ²¡æœ‰æ‰¾åˆ°é¢‘é“æ•°å­—è¿”å›åŸåç§°
            filtered_str=part_str.replace("CCTV", "")
        return "CCTV-"+filtered_str 
        
    elif "å«è§†" in part_str or "è¡›è¦–" in part_str:
        # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼ŒåŒ¹é…â€œå«è§†â€åé¢çš„å†…å®¹
        pattern = r'å«è§†ã€Œ.*ã€'
        # ä½¿ç”¨subå‡½æ•°æ›¿æ¢åŒ¹é…çš„å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²
        result_str = re.sub(pattern, 'å«è§†', part_str)
        return result_str
    
    return part_str



def tra_sim_convert(text): 
    return zhconv.convert(text, 'zh-hant')


#def verify_link2(link):
#    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'}
#    now=time.time()
#    try:
#        startTime = int(round(time.time() * 1000))
#        res=requests.get(link,headers=headers,timeout=5,stream=True)
#        if res.status_code == 200:
#            for k in res.iter_content(chunk_size=500000):
#                endTime = int(round(time.time() * 1000))
#                useTime = int(endTime - startTime)
#                if k and useTime <= 5000:
#                    return verify_link2(link)
#                elif useTime > 5000:
#                    return False
#                else:
#                    continue
#    except Exception:
#        pass
#    return False

def verify_link(link):
    useTime = -1
    try:
        startTime = int(round(time.time() * 1000))
        ffmpeg_command = 'ffmpeg -i "' + link + '" -vf "select=\'eq(n,0)\'" -vsync 1 -async 1 -fflags discardcorrupt -err_detect ignore_err -vframes 1 -y output.jpg'
        print(ffmpeg_command)
        process = subprocess.Popen(ffmpeg_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)  
        stdout, stderr = process.communicate(timeout=30)
        if process.returncode == 0:
            endTime = int(round(time.time() * 1000))
            useTime = int(endTime - startTime)
            print("=== ffmpegè½¬ç å®Œæˆ ====")    
            return useTime
        else:
            return useTime
    except Exception as e:
        print(str(e))
        return useTime

def write_file(str,filename, mode):
    with open(filename, mode, encoding='utf-8') as file:
        file.write(str+"\n")

def get_uniq_type(ctype):
    global chtype
    for key in chtype.keys():
        for l in chtype[key]:
            if l in ctype:
                return key
    return ctype

def check_exclude(ctype):
    global excludetype
    for ex in excludetype:
        if ex in ctype:
            return True
    return False

def check_exists(mydict, link):    
    for values in mydict.values():
        for line in values:
            channel_address=line.split(",")[1]
            if link == channel_address:
                return True
    return False    
    
type_mapping = {
    "Entertainment" : "ç¶œè—",
    "Generic" : "ç¶œåˆ",
    "Kids" : "å…’ç«¥",
    "Knowledge" : "çŸ¥è­˜",
    "Movies" : "é›»å½±",
    "News" : "æ–°è",
    "Other" : "å…¶å®ƒ",
    "Sports" : "é‹å‹•",
    "Music" : "éŸ³ä¹",
}

def get_channel_type(type_name):
    if type_name in type_mapping.keys():
        return type_mapping[type_name]
    else:
        return type_name


def process_url(mydict, lines, url):     
    try:
        channel_name=""
        channel_address=""
        channel_type="æœªçŸ¥"
        # é€è¡Œå¤„ç†å†…å®¹            
        for line in lines:
            line=line.strip()
            if line.startswith('#'):
                continue
            if  "#genre#" in line and "," in line:
                channel_type=line.split(",")[0].strip()
                channel_type=get_channel_type(get_uniq_type(channel_type))
                continue
            if  "#genre#" not in line and "," in line and ":" in line:
                channel_name=remove_brackets(line.split(',')[0].strip())
                channel_address=line.split(',')[1].strip()
                if len(channel_name) == 0 or check_exclude(channel_type) or check_exists(mydict, channel_address):
                    continue
                if channel_type not in mydict.keys():
                    mydict[channel_type] = []
                write_file(line.strip() + "\n","my.log","w")
                mydict[channel_type].append(process_name_string(channel_name + "," + channel_address))
                continue
    except Exception as e:
        print(f"å¤„ç†URLæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")



def process_tvname_url(mydict, lines, url):     
    try:
        channel_name=""
        channel_address=""
        channel_type="æœªåˆ†ç±»"
        # é€è¡Œå¤„ç†å†…å®¹            
        for line in lines:
            line=line.strip()
            if line.startswith('#'):
                continue
            if  "#genre#" in line and "," in line:
                continue
            if  "#genre#" not in line and "," in line and ":" in line:
                channel_name=remove_brackets(line.split(',')[0].strip())
                channel_address=line.split(',')[1].strip()
                if len(channel_name) == 0 or check_exists(mydict, channel_address):
                    continue
                if "CCTV" in channel_name.upper():
                    channel_type="å¤®è§†é¢‘é“"
                elif "å«è§†" in channel_name.upper() or "è¡›è¦–" in channel_name.upper():
                    channel_type="å«è§†é¢‘é“"
                elif "ä¸­å¤©" in channel_name.upper():
                    channel_type="ç¶œåˆ"
                else:
                    channel_type="æœªåˆ†ç±»"
                channel_type=get_channel_type(channel_type)
                if channel_type not in mydict.keys():
                    mydict[channel_type] = []
                write_file(line.strip() + "\n","my.log","w")
                mydict[channel_type].append(process_name_string(channel_name + "," + channel_address))
                continue
    except Exception as e:
        print(f"å¤„ç†URLæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

#current_directory = os.getcwd()  #å‡†å¤‡è¯»å–txt

#è¯»å–æ–‡æœ¬æ–¹æ³•
#def read_txt_to_array(file_name):
#    try:
#        with open(file_name, 'r', encoding='utf-8') as file:
#            lines = file.readlines()
#            lines = [line.strip() for line in lines]
#            return lines
#    except FileNotFoundError:
#        print(f"File '{file_name}' not found.")
#        return []
#    except Exception as e:
#        print(f"An error occurred: {e}")
#        return []


def verify(lines):
    sub_channel={}
    for line in lines:
        linesa=line.split(',')
        if len(linesa)<2:
            continue
        channel_name=linesa[0].strip()
        channel_address=linesa[1].strip()
        useTime = verify_link(channel_address)
        if useTime > -1:
            if channel_name not in sub_channel.keys():
                sub_channel[channel_name]=[]
            sub_channel[channel_name].append([channel_name, channel_address, useTime])
    for k in sub_channel.keys():
        sub_channel[k]=sorted(sub_channel[k], key=lambda t: t[2])
    ch_name_list=sorted(sub_channel.keys())
    print(ch_name_list)
    channel_list = []
    for ch in ch_name_list:
        channel_list = channel_list + [ item_list[0] + ',' + item_list[1] + ',' + str(item_list[2]) for item_list in sub_channel[ch]]
    return channel_list

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œæå–æ¯è¡Œä¸­é€—å·å‰é¢çš„æ•°å­—éƒ¨åˆ†ä½œä¸ºæ’åºçš„ä¾æ®
def extract_number(s):
    num_str = s.split(',')[0].split('-')[1]  # æå–é€—å·å‰é¢çš„æ•°å­—éƒ¨åˆ†
    numbers = re.findall(r'\d+', num_str)   #å› ä¸ºæœ‰+å’ŒK
    return int(numbers[-1]) if numbers else 999

# å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰æ’åºå‡½æ•°
def custom_sort(s):
    if "CCTV-4K" in s:
        return 1  # å°†åŒ…å« "4K" çš„å­—ç¬¦ä¸²æ’åœ¨åé¢
    elif "CCTV-8K" in s:
        return 2  # å°†åŒ…å« "8K" çš„å­—ç¬¦ä¸²æ’åœ¨åé¢
    else:
        return 0  # å…¶ä»–å­—ç¬¦ä¸²ä¿æŒåŸé¡ºåº

import re
 
def remove_brackets(s):
    return re.sub(r'\[.*?\]|{.*}|\(.*\)', '', s)

#####å¼€å§‹#################################

# å®šä¹‰è¦è®¿é—®çš„å¤šä¸ªURL
urls = [
    'https://raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt',
    'https://raw.githubusercontent.com/Guovin/TV/gd/result.txt', #1å¤©è‡ªåŠ¨æ›´æ–°1æ¬¡
    'https://raw.githubusercontent.com/ssili126/tv/main/itvlist.txt',
    'https://raw.githubusercontent.com/gaotianliuyun/gao/master/list.txt',
    'https://raw.githubusercontent.com/mlvjfchen/TV/main/iptv_list.txt',
    'https://raw.githubusercontent.com/fenxp/iptv/main/live/ipv6.txt',  #1å°æ—¶è‡ªåŠ¨æ›´æ–°1æ¬¡11:11 2024/05/13
    'https://raw.githubusercontent.com/fenxp/iptv/main/live/tvlive.txt', #1å°æ—¶è‡ªåŠ¨æ›´æ–°1æ¬¡11:11 2024/05/13
    'https://raw.githubusercontent.com/qist/tvbox/master/list.txt',
    'https://raw.githubusercontent.com/qist/tvbox/master/tvboxtv.txt',
    'https://raw.githubusercontent.com/qist/tvbox/master/tvlive.txt',
    'https://m3u.ibert.me/txt/fmml_ipv6.txt',
    'https://m3u.ibert.me/txt/ycl_iptv.txt',
    'https://m3u.ibert.me/txt/y_g.txt',
    'https://m3u.ibert.me/txt/j_home.txt',
    'https://gitee.com/xxy002/zhiboyuan/raw/master/zby.txt',
    'https://raw.githubusercontent.com/xianyuyimu/TVBOX-/main/TVBox/%E4%B8%80%E6%9C%A8%E7%9B%B4%E6%92%AD%E6%BA%90.txt',
    'https://raw.githubusercontent.com/ssili126/tv/main/itvlist.txt',
    'https://fanmingming.com/txt?url=https://live.fanmingming.com/tv/m3u/ipv6.m3u',
]

m3u_urls = [
    'https://raw.githubusercontent.com/Ftindy/IPTV-URL/main/dzh.m3u',
    'https://raw.githubusercontent.com/Ftindy/IPTV-URL/main/ghyx.m3u',    
    'https://raw.githubusercontent.com/Ftindy/IPTV-URL/main/bestv.m3u',
    'https://raw.githubusercontent.com/Ftindy/IPTV-URL/main/IPTV.m3u',    
    'https://raw.githubusercontent.com/Ftindy/IPTV-URL/main/sxg.m3u',
]

mydict = {}

chtype={}
chtype['å«è§†é¢‘é“']=['ğŸ‡¨ğŸ‡³ï½œå«è§†é¢‘é“', 'ğŸ‡¨ğŸ‡³ï½œå«è§†è“å…‰é¢‘é“', 'å«è§†é¢‘é“', 'å«è§†', 'â€¢å«è§†ã€ŒIPV6ã€', 'å«è§†å°']
chtype['å¤®è§†é¢‘é“']=['ğŸ‡¨ğŸ‡³ï½œå¤®è§†é¢‘é“', 'å¤®è§†é¢‘é“', 'CCTV', 'æ•°å­—é¢‘é“', 'ç»¼åˆ', 'å¤®è§†', 'æ•°å­—', 'â€¢å¤®è§†ã€ŒIPV6ã€', 'å¤®è§†å°', 'æ•°å­—ç”µè§†', 'å¤®è§†å…¶ä»–']
chtype['æ¸¯æ¾³å°']=['æ¸¯å°', 'ğŸ‡¨ğŸ‡³ï½œæ¸¯æ¾³å°', 'æ¸¯Â·æ¾³Â·å°', 'æ¸¯æ¾³é¢‘é“', 'å°æ¹¾é¢‘é“', 'æ¸¯æ¾³å°', 'å‡¤å‡°', 'é¦™æ¸¯']
chtype['4Ké¢‘é“']=['4K', '4Ké¢‘é“', 'ğŸ‡¨ğŸ‡³ï½œè“å…‰é¢‘é“']
chtype['ä½“è‚²é¢‘é“']=['ğŸ‡¨ğŸ‡³ï½œä½“è‚²é¢‘é“', 'ä½“è‚²é¢‘é“']
chtype['æ˜¥æ™š']=['æ˜¥æ™š', 'å†å¹´æ˜¥æ™š', 'å†å±Šæ˜¥æ™š']
chtype['NEWTV']=['NEWTV', 'â€¢NewTVã€ŒIPV6ã€']
chtype['å°‘å„¿åŠ¨ç”»']=['ğŸ‡¨ğŸ‡³ï½œå°‘å„¿åŠ¨ç”»', 'å°‘å„¿åŠ¨ç”»']
chtype['ç”µå°']=['ğŸ‡¨ğŸ‡³â€¢ç”µå°', 'ç”µå°']
chtype['å°‘å„¿åŠ¨ç”»']=['ğŸ‡¨ğŸ‡³ï½œæ¸¯æ¾³å°', 'ğŸ‡¨ğŸ‡³ï½œæ¸¯æ¾³å°']



excludetype=['ç©å¶', 'éº»è±†-MSD', 'rostelekom', 'èƒ¡å¿—è‰¯', 'Adult', 'æˆäººç‚¹æ’­', 'æ—¥æœ¬', 'æ¬§ç¾', 'è‚¥ç¾Š', 'æ›´æ–°æ—¶é—´', 'YouTube', 'ç‰¹è‰²é¢‘é“', 'åŸ‹æ¨æ¨', 'è§£è¯´é¢‘é“', 'è™ç‰™æ–—é±¼', 'â€¢æ¸¸æˆèµ›äº‹', 'æ˜¥æ™š', 'å†å¹´æ˜¥æ™š', 'å†å±Šæ˜¥æ™š', 'BESTV']

import sys

if len(sys.argv)==1:
    print("ä½¿ç”¨æ–¹æ³•ï¼š")
    print("       python3 main.py init           #åˆå§‹åŒ–å¹¶éªŒè¯githubé¢‘é“åˆ—è¡¨")
    print("       python3 main.py checkvalid     #æ£€æŸ¥é¢‘é“æºæœ‰æ•ˆé¢‘é“æ•°")
    print("       python3 main.py epgpw download #ä¸‹è½½å¹¶éªŒè¯epg.pwé¢‘é“åˆ—è¡¨") 
    print("       python3 main.py epgpw skip     #ä¸ä¸‹è½½å¹¶éªŒè¯epg.pwé¢‘é“åˆ—è¡¨") 
    sys.exit()

write_file("","my.log","w")
#åˆå§‹åŒ–
oper=sys.argv[1]
if oper == "init":

    files=['dog.txt', 'output.txt']
    for f in files:
        with open(f, 'r', encoding='utf-8') as file:
           lines = file.readlines()
           process_url(mydict, lines, f)

    #å¾ªç¯å¤„ç†æ¯ä¸ªURL
    for url in urls:
        url=url.replace('https://raw.githubusercontent.com/','https://hub.gitmirror.com/https://raw.githubusercontent.com/')
        #url=url.replace('githubusercontent.com','staticdn.net')
        #æ‰“å¼€URLå¹¶è¯»å–å†…å®¹
        #os.system('wget ' + url + " -O my.txt")
        os.system('curl ' + url + " -o my.txt")
        with open('my.txt', 'r', encoding='utf-8') as file:
           lines = file.readlines()
           process_url(mydict, lines, url)
    
    #å¾ªç¯å¤„ç†æ¯ä¸ªM3U URL
    for url in m3u_urls:
        url=url.replace('https://raw.githubusercontent.com/','https://hub.gitmirror.com/https://raw.githubusercontent.com/')
        #url=url.replace('githubusercontent.com','staticdn.net')
        #æ‰“å¼€URLå¹¶è¯»å–å†…å®¹
        os.system('curl ' + url + " -o my.m3u")
        m3u_to_txt('my.m3u', 'my.txt')
        with open('my.txt', 'r', encoding='utf-8') as file:
           lines = file.readlines()
           process_url(mydict, lines, url)

    
    #files = os.listdir("./history/")
    #for file in files:
    #    #print(file)
    #    if os.path.isfile("./history/" + file):
    #        with open("./history/" + file, 'r', encoding='utf-8') as file:
    #            lines = file.readlines()
    #            process_url(mydict, lines, file)
    
    
    print("start=======================================================")
    # åˆå¹¶æ‰€æœ‰å¯¹è±¡ä¸­çš„è¡Œæ–‡æœ¬ï¼ˆå»é‡ï¼Œæ’åºåæ‹¼æ¥ï¼‰
    version=datetime.now().strftime("%Y%m%d")+",url"
    all_lines =  ["æ›´æ–°æ—¶é—´,#genre#"] +[version] 
    
    for key in mydict.keys():
        write_file(key + "\n","my.log","w")
        channels=verify(sorted(set(mydict[key])))
        if len(channels) > 0:
            all_lines = all_lines + ['\n'] + [key + ",#genre#"] + channels
    
    # å°†åˆå¹¶åçš„æ–‡æœ¬å†™å…¥æ–‡ä»¶
    output_file = '../../mysite/dog.txt'
    output_file_bak = './history/dog_' + datetime.now().strftime('%Y%m%d') + '.txt'
    with open(output_file, 'w', encoding='utf-8') as f, open(output_file_bak, 'w', encoding='utf-8') as fb:
        for line in all_lines:
            linea=line.split(',')
            if len(linea) >= 2:
                channel_name=linea[0].strip()
                channel_address=linea[1].strip()                
                if len(linea) >= 3:
                    channel_source=linea[2].strip()
                    f.write(channel_name + "," + channel_address + '\n')
                    fb.write(channel_name + "," + channel_address + '\n')
                else:
                    f.write(channel_name + "," + channel_address + '\n')
                    fb.write(channel_name + "," + channel_address + '\n')
            else:
                f.write(line.strip() + '\n')
                fb.write(line.strip() + '\n')
                
    print(f"åˆå¹¶åçš„æ–‡æœ¬å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}, {output_file_bak}")
    print("done=======================================================")
elif oper == "check":
    files=['output.txt', 'dog.txt']
    for f in files:
        with open(f, 'r', encoding='utf-8') as file:
           lines = file.readlines()
           process_url(mydict, lines, f)
    
    # åˆå¹¶æ‰€æœ‰å¯¹è±¡ä¸­çš„è¡Œæ–‡æœ¬ï¼ˆå»é‡ï¼Œæ’åºåæ‹¼æ¥ï¼‰
    version=datetime.now().strftime("%Y%m%d")+",url"
    all_lines =  ["æ›´æ–°æ—¶é—´,#genre#"] +[version] 

    for key in mydict.keys():
        write_file(key + "\n","my.log","w")
        channels=verify(sorted(set(mydict[key])))
        if len(channels) > 0:
            print(channels)
            all_lines = all_lines + ['\n'] + [key + ",#genre#"] + channels

    print(all_lines)

    # å°†åˆå¹¶åçš„æ–‡æœ¬å†™å…¥æ–‡ä»¶
    output_file = 'dog.txt'

    with open(output_file, 'w', encoding='utf-8') as f:
        for line in all_lines:
            linea=line.split(',')
            if len(linea) >= 2:
                channel_name=linea[0].strip()
                channel_address=linea[1].strip()                
                if len(linea) >= 3:
                    channel_source=linea[2].strip()
                    f.write(channel_name + "," + channel_address + '\n')
                else:
                    f.write(channel_name + "," + channel_address + '\n')
            else:
                f.write(line.strip() + '\n')                
    print(f"åˆå¹¶åçš„æ–‡æœ¬å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")
    print("done=======================================================")

elif oper == "checkvalid":    
    #è·å–æ‰€æœ‰çš„æœ‰æ•ˆçš„é“¾æ¥
    all_valid=[]
    files=['dog.txt', 'output.txt']
    for f in files:
        with open(f, 'r', encoding='utf-8') as file:
           lines = file.readlines()
           for line in lines:
               linea=line.split(',')
               if len(linea) >= 2:
                   all_valid.append(linea[1].strip())
    print(all_valid)
    #å¾ªç¯å¤„ç†æ¯ä¸ªURL
    for url in urls:
        url=url.replace('https://raw.githubusercontent.com/','https://hub.gitmirror.com/https://raw.githubusercontent.com/')
        #url=url.replace('githubusercontent.com','staticdn.net')
        #æ‰“å¼€URLå¹¶è¯»å–å†…å®¹
        #os.system('wget ' + url + " -O my.txt")
        os.system('curl ' + url + " -o my.txt")
        with open('my.txt', 'r', encoding='utf-8') as file:
            valid_count=0
            lines = file.readlines()
            for line in lines:
                linea=line.split(',')
                if len(linea) >= 2 and linea[1].strip() != '#genre#' and linea[1].strip() in all_valid:
                   #print(line)
                   valid_count = valid_count + 1
            print(url + ": " + str(valid_count))
    
    #å¾ªç¯å¤„ç†æ¯ä¸ªM3U URL
    for url in m3u_urls:
        url=url.replace('https://raw.githubusercontent.com/','https://hub.gitmirror.com/https://raw.githubusercontent.com/')
        #url=url.replace('githubusercontent.com','staticdn.net')
        #æ‰“å¼€URLå¹¶è¯»å–å†…å®¹
        os.system('curl ' + url + " -o my.m3u")
        m3u_to_txt('my.m3u', 'my.txt')
        with open('my.txt', 'r', encoding='utf-8') as file:
            lines = file.readlines()
            valid_count=0
            for line in lines:
                linea=line.split(',')
                if len(linea) >= 2 and linea[1].strip() != '#genre#' and linea[1].strip() in all_valid:
                   #print(line)
                   valid_count = valid_count + 1
            print(url + ": " + str(valid_count))
    
elif oper == "epgpw":
    skipdownload=sys.argv[2]
    all_types=['ä¸­åœ‹å¤§é™¸', 'é¢‘é“ä¸ç¬¦åˆä»»ä½•EPG', 'å°ç£', 'é¦™æ¸¯', 'æ¾³é–€', 'ç¾åœ‹', 'æ–°åŠ å¡', 'è‹±åœ‹', 'æ¾³å¤§åˆ©äº', 'åŠ æ‹¿å¤§', 'æ–°è¥¿è˜­']
    file_prefix = os.path.dirname(os.path.abspath(__file__)) + "/epgpw/"
    if skipdownload == "download":
        #ä¸‹è½½æ‰€æœ‰é¢‘é“
        all_links={}
        x = requests.get('https://epg.pw/test_channel_page.html?lang=zh-hans')
        #print(x.text)
        soup = BeautifulSoup(x.text, 'html5lib')
        all_trs = soup.find_all('tr')
        print(os.path.dirname(os.path.abspath(__file__)))
        for tr in all_trs:
            all_tds = tr.find_all('td')
            if len(all_tds) == 3:
                link=all_tds[0].text.strip()
                type_name=all_tds[2].text.strip()
                file_name= file_prefix + all_tds[2].text.strip() + ".txt"
                if not link.endswith("_original_new.txt") and \
                        link.endswith("_new.txt") and \
                        type_name in all_types and \
                        "banned" not in link and \
                        link not in all_links.values():
                    all_links[type_name]=link                
                    print(all_tds[2].text.strip())
                    os.system('curl ' + link + " -o " + file_name) 
                    time.sleep(5)
        for key, value in all_links.items():
            print(key + " : " + value + "\n")

    #ä¸­å›½å¤§é™†
    china_main=['ä¸­åœ‹å¤§é™¸']
    files=[file_prefix + type + ".txt" for type in  china_main]
    print(files)
    for f in files:
        with open(f, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            process_tvname_url(mydict, lines, f)

    #æ¸¯æ¾³å°ä¸–ç•Œ
    gat_types=['å°ç£', 'é¦™æ¸¯', 'æ¾³é–€', 'ç¾åœ‹', 'æ–°åŠ å¡', 'è‹±åœ‹', 'æ¾³å¤§åˆ©äº', 'åŠ æ‹¿å¤§', 'æ–°è¥¿è˜­']
    mydict={}
    files=[file_prefix + type + ".txt" for type in  gat_types]
    print(files)
    for f in files:
        with open(f, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            process_url(mydict, lines, f)
    
    #å…¶ä»–
    unclassfied=['é¢‘é“ä¸ç¬¦åˆä»»ä½•EPG']
    files=[file_prefix + type + ".txt" for type in unclassfied]
    print(files)
    for f in files:
        with open(f, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            process_tvname_url(mydict, lines, f)
    
    # åˆå¹¶æ‰€æœ‰å¯¹è±¡ä¸­çš„è¡Œæ–‡æœ¬ï¼ˆå»é‡ï¼Œæ’åºåæ‹¼æ¥ï¼‰
    version=datetime.now().strftime("%Y%m%d")+",url"
    all_lines =  ["æ›´æ–°æ—¶é—´,#genre#"] +[version] 

    for key in mydict.keys():
        write_file(key + "\n","my.log","w")
        channels=verify(sorted(set(mydict[key])))
        if len(channels) > 0:
            print(channels)
            all_lines = all_lines + ['\n'] + [key + ",#genre#"] + channels

    print(all_lines)

    # å°†åˆå¹¶åçš„æ–‡æœ¬å†™å…¥æ–‡ä»¶
    output_file = './history/gat_epgpw_' + datetime.now().strftime('%Y%m%d') + '.txt' 
    output_mysite_file = "../../mysite/gat.txt"

    with open(output_file, 'w', encoding='utf-8') as f, open(output_mysite_file, 'w', encoding='utf-8') as fmysite:
        for line in all_lines:
            linea=line.split(',')
            if len(linea) >= 2:
                channel_name=linea[0].strip()
                channel_address=linea[1].strip()                
                if len(linea) >= 3:
                    channel_source=linea[2].strip()
                    f.write(channel_name + "," + channel_address + '\n')
                    fmysite.write(channel_name + "," + channel_address + '\n')
                else:
                    f.write(channel_name + "," + channel_address + '\n')
                    fmysite.write(channel_name + "," + channel_address + '\n')
            else:
                f.write(line.strip() + '\n')                
    print(f"åˆå¹¶åçš„æ–‡æœ¬å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file} {output_mysite_file}")

